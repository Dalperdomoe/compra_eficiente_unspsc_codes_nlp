{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(987)\n",
    "plt.style.use(\"seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file = os.path.join(\"..\", \"data\", \"raw\", \"raw_data.csv\")\n",
    "df_raw = pd.read_csv(raw_file)\n",
    "\n",
    "df_sample = df_raw.sample(10000).reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unspsc_file = os.path.join(\"..\",\"references\",\"clasificador_de_bienes_y_servicios_v14_1.xlsx\")\n",
    "df_unspsc = pd.read_excel(unspsc_file)\n",
    "\n",
    "segment_dict = dict(\n",
    "    zip(\n",
    "        df_unspsc['Código Segmento'].astype('str'),\n",
    "        df_unspsc['Nombre Segmento']\n",
    "    )\n",
    ")\n",
    "family_dict = dict(\n",
    "    zip(\n",
    "        df_unspsc['Código Familia'].astype('str'),\n",
    "        df_unspsc['Nombre Familia']\n",
    "    )\n",
    ")\n",
    "class_dict = dict(\n",
    "    zip(\n",
    "        df_unspsc['Código Clase'].astype('str'),\n",
    "        df_unspsc['Nombre Clase']\n",
    "    )\n",
    ")\n",
    "commodity_dict = dict(\n",
    "    zip(\n",
    "        df_unspsc['Código Producto'].astype('str'),\n",
    "        df_unspsc['Nombre Producto']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['codigo_de_categoria_principal'] = df_sample['codigo_de_categoria_principal'].str.extract('([0-9]{8})', expand=False)\n",
    "\n",
    "df_sample['segment_code'] = df_sample['codigo_de_categoria_principal'].str[:2]\n",
    "df_sample['family_code'] = df_sample['codigo_de_categoria_principal'].str[:4]\n",
    "df_sample['class_code'] = df_sample['codigo_de_categoria_principal'].str[:6]\n",
    "df_sample['commodity_code'] = df_sample['codigo_de_categoria_principal'].str[:8]\n",
    "\n",
    "df_sample['segment_text'] = df_sample.segment_code.map(segment_dict)\n",
    "df_sample['family_text'] = df_sample.family_code.map(family_dict)\n",
    "df_sample['class_text'] = df_sample.class_code.map(class_dict)\n",
    "df_sample['commodity_text'] = df_sample.commodity_code.map(commodity_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.keras.utils.to_categorical(df[\"Labels\"].values, num_classes=num_classes)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['Text'], y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-preprocess/2\")\n",
    "encoder = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-base/1\")\n",
    "\n",
    "def get_embeddings(sentences):\n",
    "  '''return BERT-like embeddings of input text\n",
    "  Args:\n",
    "    - sentences: list of strings\n",
    "  Output:\n",
    "    - BERT-like embeddings: tf.Tensor of shape=(len(sentences), 768)\n",
    "  '''\n",
    "  preprocessed_text = preprocessor(sentences)\n",
    "  return encoder(preprocessed_text)['pooled_output']\n",
    "\n",
    "\n",
    "get_embeddings([\n",
    "    \"Questa collezione di Haiku è una porta aperta sulla cultura giapponese.\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def balanced_recall(y_true, y_pred):\n",
    "    \"\"\"This function calculates the balanced recall metric\n",
    "    recall = TP / (TP + FN)\n",
    "    \"\"\"\n",
    "    recall_by_class = 0\n",
    "    # iterate over each predicted class to get class-specific metric\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        y_pred_class = y_pred[:, i]\n",
    "        y_true_class = y_true[:, i]\n",
    "        true_positives = K.sum(K.round(K.clip(y_true_class * y_pred_class, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true_class, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        recall_by_class = recall_by_class + recall\n",
    "    return recall_by_class / y_pred.shape[1]\n",
    "\n",
    "def balanced_precision(y_true, y_pred):\n",
    "    \"\"\"This function calculates the balanced precision metric\n",
    "    precision = TP / (TP + FP)\n",
    "    \"\"\"\n",
    "    precision_by_class = 0\n",
    "    # iterate over each predicted class to get class-specific metric\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        y_pred_class = y_pred[:, i]\n",
    "        y_true_class = y_true[:, i]\n",
    "        true_positives = K.sum(K.round(K.clip(y_true_class * y_pred_class, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred_class, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        precision_by_class = precision_by_class + precision\n",
    "    # return average balanced metric for each class\n",
    "    return precision_by_class / y_pred.shape[1]\n",
    "\n",
    "def balanced_f1_score(y_true, y_pred):\n",
    "    \"\"\"This function calculates the F1 score metric\"\"\"\n",
    "    precision = balanced_precision(y_true, y_pred)\n",
    "    recall = balanced_recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "x = preprocessor(i)\n",
    "x = encoder(x)\n",
    "x = tf.keras.layers.Dropout(0.2, name=\"dropout\")(x['pooled_output'])\n",
    "x = tf.keras.layers.Dense(num_classes, activation='softmax', name=\"output\")(x)\n",
    "\n",
    "model = tf.keras.Model(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "METRICS = [\n",
    "      tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "      balanced_recall,\n",
    "      balanced_precision,\n",
    "      balanced_f1_score\n",
    "]\n",
    "\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", \n",
    "                                                      patience = 3,\n",
    "                                                      restore_best_weights = True)\n",
    "\n",
    "model.compile(optimizer = \"adam\",\n",
    "              loss = \"categorical_crossentropy\",\n",
    "              metrics = METRICS)\n",
    "\n",
    "model_fit = model.fit(x_train, \n",
    "                      y_train, \n",
    "                      epochs = n_epochs,\n",
    "                      validation_data = (x_test, y_test),\n",
    "                      callbacks = [earlystop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(1, n_epochs+1))\n",
    "metric_list = list(model_fit.history.keys())\n",
    "num_metrics = int(len(metric_list)/2)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=num_metrics, figsize=(30, 5))\n",
    "\n",
    "for i in range(0, num_metrics):\n",
    "  ax[i].plot(x, model_fit.history[metric_list[i]], marker=\"o\", label=metric_list[i].replace(\"_\", \" \"))\n",
    "  ax[i].plot(x, model_fit.history[metric_list[i+num_metrics]], marker=\"o\", label=metric_list[i+num_metrics].replace(\"_\", \" \"))\n",
    "  ax[i].set_xlabel(\"epochs\",fontsize=14)\n",
    "  ax[i].set_title(metric_list[i].replace(\"_\", \" \"),fontsize=20)\n",
    "  ax[i].legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(reviews):\n",
    "  '''predict class of input text\n",
    "  Args:\n",
    "    - reviews (list of strings)\n",
    "  Output:\n",
    "    - class (list of int)\n",
    "  '''\n",
    "  return [np.argmax(pred) for pred in model.predict(reviews)]\n",
    "\n",
    "\n",
    "predict_class(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blind set evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/text_classifier_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the model as needed for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# load model\n",
    "new_model = keras.models.load_model(\"/models/text_classifier_v1\")\n",
    "\n",
    "# test predictions\n",
    "[np.argmax(pred) for pred in new_model.predict(reviews)]\n",
    "# output: [3, 1, 0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3f966273feecc803f70756ec54d7ac99871d4b8828d7b4125d8f9ec98086622"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
